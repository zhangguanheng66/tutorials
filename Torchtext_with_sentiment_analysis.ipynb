{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torchtext with sentiment analysis",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangguanheng66/tutorials/blob/sentiment_analysis/Torchtext_with_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMg-_Db4xil_",
        "outputId": "7ed3ff33-2b64-47be-c6d9-2ddee8efac4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%shell\n",
        "\n",
        "rm -r /usr/local/lib/python3.6/dist-packages/torch*\n",
        "#pip uninstall torch torchtext\n",
        "#pip install --pre torch torchvision torchtext -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
        "pip install --pre torch torchvision torchtext -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu101/torch-1.8.0.dev20201008%2Bcu101-cp36-cp36m-linux_x86_64.whl (737.4MB)\n",
            "\u001b[K     |████████████████████████████████| 737.4MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu101/torchvision-0.8.0.dev20201008%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.9MB)\n",
            "\u001b[K     |████████████████████████████████| 24.9MB 100kB/s \n",
            "\u001b[?25hCollecting torchtext\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/torchtext-0.8.0.dev20201008-cp36-cp36m-linux_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Installing collected packages: torch, torchvision, sentencepiece, torchtext\n",
            "Successfully installed sentencepiece-0.1.91 torch-1.8.0.dev20201008+cu101 torchtext-0.8.0.dev20201008 torchvision-0.8.0.dev20201008+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjjwtY1Exr-e",
        "outputId": "f34b45e6-b23c-4af8-d7fb-9771ac92fac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.__file__)\n",
        "import torchtext\n",
        "print(torchtext.__version__)\n",
        "print(torchtext.__file__)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.0.dev20201008+cu101\n",
            "/usr/local/lib/python3.6/dist-packages/torch/__init__.py\n",
            "0.8.0.dev20201008\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/__init__.py\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIBfeik3xzT-"
      },
      "source": [
        "# Prototype pipeline with the new torchtext library\n",
        "\n",
        "In this tutorial, we will show how to use the new torchtext library to build the dataset for the text classification analysis. In the nightly release of torchtext libraries, we provide a few prototype building blocks for data processing. With the new torchtext library, you will have the flexibility to\n",
        "\n",
        "*   Access to the raw data as an iterator\n",
        "*   Build data processing pipeline to convert the raw text strings into `torch.Tensor` that can be used to train the model\n",
        "*   Shuffle and iterate the data with `torch.utils.data.DataLoader`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzujHlKmQvr1"
      },
      "source": [
        "## Step 1: Access to the raw dataset iterators\n",
        "----------------------------\n",
        "\n",
        "For some advanced users, they prefer to work on the raw data strings with their custom data process pipeline. The new torchtext library provides a few raw dataset iterators, which yield the raw text strings. For example, the AG_NEWS dataset iterators yield the raw data as a tuple of label and text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTTFwHimQunR",
        "outputId": "4fb0590f-6a69-4844-98ac-cd87be30161d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchtext.experimental.datasets.raw import AG_NEWS\n",
        "train_iter, = AG_NEWS(data_select=('train'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.csv: 29.5MB [00:00, 70.5MB/s]\n",
            "test.csv: 1.86MB [00:00, 24.8MB/s]                  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb0APgAhRO-P"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "next(iter(train_iter))\n",
        ">>> (3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - \n",
        "Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green \n",
        "again.\")\n",
        "\n",
        "next(iter(train_iter))\n",
        ">>> (3, 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private \n",
        "investment firm Carlyle Group,\\\\which has a reputation for making well-timed \n",
        "and occasionally\\\\controversial plays in the defense industry, has quietly \n",
        "placed\\\\its bets on another part of the market.')\n",
        "\n",
        "next(iter(train_iter))\n",
        ">>> (3, \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring \n",
        "crude prices plus worries\\\\about the economy and the outlook for earnings are \n",
        "expected to\\\\hang over the stock market next week during the depth of \n",
        "the\\\\summer doldrums.\")\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0hKv5a9yBh2"
      },
      "source": [
        "## Step 2: Prepare data processing pipelines\n",
        "----------------------------\n",
        "We have revisited the very basic components of the torchtext library, including vocab, word vectors, tokenizer backed by regular expression, and sentencepiece. Those are the basic data processing building blocks for raw text string.\n",
        "\n",
        "### 2.1 Tokenizer-vocabulary data processing pipeline\n",
        "\n",
        "Here is an example for typical NLP data processing with tokenizer and vocabulary.\n",
        "\n",
        "The first step is to build a vocabulary with the raw training dataset. We provide a function `build_vocab_from_iterator` to build the vocabulary from a text iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ8e0CPfNSBU"
      },
      "source": [
        "from torchtext.experimental.vocab import build_vocab_from_iterator\n",
        "from torchtext.experimental.transforms import basic_english_normalize\n",
        "tokenizer = basic_english_normalize()\n",
        "train_iter, = AG_NEWS(data_select=('train'))\n",
        "vocab = build_vocab_from_iterator(iter(tokenizer(line) for label, line in train_iter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skoJqORdQDdM"
      },
      "source": [
        "The vocabulary block converts a list of tokens into integers.\n",
        "```\n",
        "vocab(['here', 'is', 'an', 'example'])\n",
        ">>> [475, 21, 30, 5286]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBhnX9u-ya6T"
      },
      "source": [
        "Prepare data pipeline with the tokenizer and vocabulary. The pipelines will be used for the raw data strings from the dataset iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC4gaPr5ybzQ"
      },
      "source": [
        "def generate_text_pipeline(tokenizer, vocab):\n",
        "  def _forward(text):\n",
        "    return vocab(tokenizer(text))\n",
        "  return _forward\n",
        "text_pipeline = generate_text_pipeline(basic_english_normalize(), vocab)\n",
        "#label_pipeline = lambda x: 1 if x == 'pos' else 0\n",
        "label_pipeline = lambda x: int(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsZYFwWiUKJ_"
      },
      "source": [
        "The text piple converts a text string into a list of integers based on the lookup defined in the vocab. The label pipeline converts the label into integers. For example,\n",
        "\n",
        "```\n",
        "text_pipeline('here is the an example')\n",
        ">>> [475, 21, 2, 30, 5286]\n",
        "label_pipeline('10')\n",
        ">>> 10\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLNPAmG-zBtC"
      },
      "source": [
        "### 2.2 SentencePiece data processing pipeline\n",
        "\n",
        "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. For sentencepiece transforms in torchtext, both subword units (e.g., byte-pair-encoding (BPE) ) and unigram language model are supported. We provide a few pretrained SentencePiece models and they are accessable from `PRETRAINED_SP_MODEL`. Here is an example to apply SentencePiece transform to build the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EMgLIfzScN",
        "outputId": "bd3311b2-4a6d-4baf-a3c6-1420d5bc797e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchtext.experimental.transforms import (\n",
        "    PRETRAINED_SP_MODEL,\n",
        "    sentencepiece_processor,\n",
        "    load_sp_model,\n",
        ")\n",
        "from torchtext.utils import download_from_url\n",
        "spm_filepath = download_from_url(PRETRAINED_SP_MODEL['text_unigram_25000'])\n",
        "spm_transform = sentencepiece_processor(spm_filepath)\n",
        "sp_model = load_sp_model(spm_filepath)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text_unigram_25000.model: 100%|██████████| 678k/678k [00:00<00:00, 1.66MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L42bQso4XUa"
      },
      "source": [
        "The sentecepiece processor converts a text string into a list of integers. You can use the `decode` method to convert a list of integers back to the original string.\n",
        "\n",
        "```\n",
        "spm_transform('here is the an example')\n",
        ">>> [130, 46, 9, 76, 1798]\n",
        "spm_transform.decode([6468, 17151, 4024, 8246, 16887, 87, 23985, 12, 581, 15120])\n",
        ">>> 'torchtext sentencepiece processor can encode and decode'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PllfOE8-y7ye"
      },
      "source": [
        "### 2.3 (Optional for tutorial) Tokenizer + Vocab + Embedding data processing pipeline\n",
        "\n",
        "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. FastText and GloVe are well established baseline word vectors in the NLP community. In the new torchtext library, a Vector object supports the mapping between tokens and their corresponding vector representation (i.e. word embeddings)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE7D5dmdy89K"
      },
      "source": [
        "from torchtext.experimental.vectors import FastText\n",
        "def generate_vector_pipeline(tokenizer, vector):\n",
        "  def _forward(text):\n",
        "    return vector(tokenizer(text))\n",
        "  return _forward\n",
        "word_vector_pipeline = generate_vector_pipeline(basic_english_normalize(), FastText())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iZ5wFUMk0OW"
      },
      "source": [
        "The word_vector_pipeline tokenizes a text string and converts the tokenzers into a vector, according to the pretrained word vector.\n",
        "\n",
        "```\n",
        "word_vector_pipeline('here is the an example')\n",
        ">>> tensor([[-0.1564,  0.0486,  0.1724,  ...,  0.4588, -0.0021,  0.3085],\n",
        "            [ 0.0359,  0.1452,  0.1193,  ..., -0.0016,  0.1708, -0.0355],\n",
        "            [-0.0653, -0.0930, -0.0176,  ...,  0.1664, -0.1308,  0.0354],\n",
        "            [-0.0671,  0.0014, -0.1857,  ...,  0.1050, -0.2144,  0.0944],\n",
        "            [ 0.0144,  0.1337, -0.1489,  ..., -0.0202,  0.0657, -0.0029]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXtEz6DJ2i7M"
      },
      "source": [
        "## Step 3: Generate data batch and iterator¶\n",
        "\n",
        "The PyTorch data loading utility is the `torch.utils.data.DataLoader` class. It works with a map-style dataset that implements the `getitem()` and `len()` protocols, and represents a map from indices/keys to data samples. It also works with an iterable datasets with the shuffle argumnet of `False`. Before sending to the model, `collate_fn` function works on a batch of samples generated from DataLoader and we can add the data processing pipelines in Step 2 to the `collate_fn` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvWw9sVE2idq"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# [TODO] integrate with torchtext.experimental.transforms.PadTransform\n",
        "# Need to land https://github.com/pytorch/text/pull/952\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "cls_id = sp_model.PieceToId('<cls>')\n",
        "pad_id = sp_model.PieceToId('<pad>')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        text_list.append(torch.tensor([cls_id] + spm_transform(_text)))\n",
        "    text_list = pad_sequence(text_list, batch_first=True, padding_value=float(pad_id))\n",
        "    label_list = torch.tensor(label_list)\n",
        "    return label_list.to(device), text_list.transpose(0, 1).contiguous().to(device)\n",
        "\n",
        "train_iter, = AG_NEWS(data_select=('train'))\n",
        "dataloader = DataLoader(list(train_iter), batch_size=8, shuffle=True, collate_fn=collate_batch)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNbi1He69ANc"
      },
      "source": [
        "## Step 4: Model for text classification task\n",
        "---\n",
        "\n",
        "We use a transformer model here for the text classification analysis. The model is composed of an embedding layer plus a positional encoding layer. Following those two, we have the transformer model and a linear layer is attached to the end for the classification purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLJYfMlq9HjU"
      },
      "source": [
        "from torch import nn\n",
        "import math\n",
        "NUM_CLASSES = 5\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "    \"\"\"Contain a transformer encoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embed_layer = nn.Embedding(ntoken, ninp)\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.activation = nn.Tanh()\n",
        "        self.projection = nn.Linear(ninp, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, src_seq):\n",
        "        output = self.embed_layer(src_seq)\n",
        "        output = self.pos_encoder(output)\n",
        "        output = self.transformer_encoder(output)\n",
        "        output = self.activation(output[0])\n",
        "        return self.projection(output)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCCaM9x_6rIN"
      },
      "source": [
        "We build a model with the following parameters\n",
        "\n",
        "\n",
        "*   the embedding dimension - 64\n",
        "*   the number of heads in the transformer model - 8\n",
        "*   the hidden dimension in the transformer model - 128\n",
        "*   the number of layers in the transformer model - 1\n",
        "*   the dropout value - 0.2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfyBKOxg_kg5"
      },
      "source": [
        "vocab_size = sp_model.GetPieceSize()\n",
        "emsize, nhead, nhid, nlayers, dropout = 64, 8, 128, 1, 0.2\n",
        "model = TextClassificationModel(vocab_size, emsize, nhead, nhid, nlayers, dropout).to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iovYWRYFBHnc"
      },
      "source": [
        "\n",
        "## Step 5: Train and test the model\n",
        "---\n",
        "\n",
        "Then, we train and test the transformer model with the text classification datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngQ1bnGlBZ0k"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def fine_tune(model, dataloader, optimizer, criterion, batch_size, device, SEQENCE_LENGTH):\n",
        "    model.train()\n",
        "    total_loss, total_acc, total_count = 0, 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        # print(seq_input.size(), tok_type.size())\n",
        "        if text.size(0) > SEQENCE_LENGTH:\n",
        "            text = text[:SEQENCE_LENGTH]\n",
        "        predited_label = model(text)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        #print(predited_label.argmax(1), label)\n",
        "        total_count += text.size(1)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | '\n",
        "                  'ms/batch {:5.2f} | loss {:5.2f} '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              scheduler.get_last_lr()[0],\n",
        "                                              elapsed * 1000 / log_interval,\n",
        "                                              cur_loss, total_acc/total_count))\n",
        "            total_loss, total_acc, total_count = 0, 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model, dataloader, optimizer,\n",
        "             criterion, batch_size, device, SEQENCE_LENGTH):\n",
        "    model.eval()\n",
        "    total_loss, total_acc, total_count = 0, 0, 0\n",
        "    ans_pred_tokens_samples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text) in enumerate(dataloader):\n",
        "            if text.size(0) > SEQENCE_LENGTH:\n",
        "              text = text[:SEQENCE_LENGTH]\n",
        "            predited_label = model(text)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_loss += loss.item()\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += text.size(1)\n",
        "    return total_loss / len(dataloader), total_acc/total_count"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSBskbHkQ3Ll"
      },
      "source": [
        "Here are a few hyperparameters used in the pipeline\n",
        "\n",
        "\n",
        "*   The number of epoches - 10\n",
        "*   The initial learning rate - 5.0\n",
        "*   The batch size - 64\n",
        "*   The maximum sequence length - 768\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXD1I31kCE2T",
        "outputId": "4cda0b24-f101-462e-ee45-dc6d7f20250a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "SEQENCE_LENGTH = 768 # the maximum sequence length\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = AG_NEWS()\n",
        "train_dataloader = DataLoader(list(train_iter), batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(list(test_iter), batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    fine_tune(model, train_dataloader, optimizer,\n",
        "              criterion, BATCH_SIZE, device, SEQENCE_LENGTH)\n",
        "    loss_val, accu_val = evaluate(model, test_dataloader, optimizer,\n",
        "                                  criterion, BATCH_SIZE, device, SEQENCE_LENGTH)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid loss {:5.2f} | valid accuracy {:8.3f} '.format(epoch,\n",
        "                                         (time.time() - epoch_start_time),\n",
        "                                         loss_val, accu_val))\n",
        "    print('-' * 89)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.56 | loss  1.34 | accuracy    0.360\n",
            "| epoch   1 |  1000/ 1875 batches | lr 5.00000 | ms/batch 34.37 | loss  1.08 | accuracy    0.541\n",
            "| epoch   1 |  1500/ 1875 batches | lr 5.00000 | ms/batch 34.65 | loss  0.98 | accuracy    0.589\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 66.76s | valid loss  0.75 | valid accuracy    0.707 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.60 | loss  0.89 | accuracy    0.639\n",
            "| epoch   2 |  1000/ 1875 batches | lr 5.00000 | ms/batch 34.22 | loss  0.84 | accuracy    0.665\n",
            "| epoch   2 |  1500/ 1875 batches | lr 5.00000 | ms/batch 34.77 | loss  0.80 | accuracy    0.680\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 66.30s | valid loss  0.61 | valid accuracy    0.776 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.27 | loss  0.74 | accuracy    0.718\n",
            "| epoch   3 |  1000/ 1875 batches | lr 5.00000 | ms/batch 35.05 | loss  0.71 | accuracy    0.727\n",
            "| epoch   3 |  1500/ 1875 batches | lr 5.00000 | ms/batch 35.11 | loss  0.68 | accuracy    0.742\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 66.61s | valid loss  0.53 | valid accuracy    0.808 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.61 | loss  0.64 | accuracy    0.760\n",
            "| epoch   4 |  1000/ 1875 batches | lr 5.00000 | ms/batch 35.11 | loss  0.62 | accuracy    0.766\n",
            "| epoch   4 |  1500/ 1875 batches | lr 5.00000 | ms/batch 33.92 | loss  0.61 | accuracy    0.771\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 66.82s | valid loss  0.48 | valid accuracy    0.828 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.35 | loss  0.58 | accuracy    0.787\n",
            "| epoch   5 |  1000/ 1875 batches | lr 5.00000 | ms/batch 35.38 | loss  0.56 | accuracy    0.795\n",
            "| epoch   5 |  1500/ 1875 batches | lr 5.00000 | ms/batch 34.74 | loss  0.56 | accuracy    0.796\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 66.93s | valid loss  0.45 | valid accuracy    0.844 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |   500/ 1875 batches | lr 5.00000 | ms/batch 35.08 | loss  0.54 | accuracy    0.808\n",
            "| epoch   6 |  1000/ 1875 batches | lr 5.00000 | ms/batch 34.65 | loss  0.53 | accuracy    0.810\n",
            "| epoch   6 |  1500/ 1875 batches | lr 5.00000 | ms/batch 34.18 | loss  0.52 | accuracy    0.813\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 66.67s | valid loss  0.42 | valid accuracy    0.854 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.88 | loss  0.50 | accuracy    0.819\n",
            "| epoch   7 |  1000/ 1875 batches | lr 5.00000 | ms/batch 34.53 | loss  0.50 | accuracy    0.818\n",
            "| epoch   7 |  1500/ 1875 batches | lr 5.00000 | ms/batch 34.67 | loss  0.49 | accuracy    0.822\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 67.32s | valid loss  0.39 | valid accuracy    0.862 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |   500/ 1875 batches | lr 5.00000 | ms/batch 34.26 | loss  0.48 | accuracy    0.829\n",
            "| epoch   8 |  1000/ 1875 batches | lr 5.00000 | ms/batch 34.98 | loss  0.48 | accuracy    0.829\n",
            "| epoch   8 |  1500/ 1875 batches | lr 5.00000 | ms/batch 34.95 | loss  0.47 | accuracy    0.833\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 67.11s | valid loss  0.41 | valid accuracy    0.854 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |   500/ 1875 batches | lr 0.50000 | ms/batch 35.17 | loss  0.43 | accuracy    0.847\n",
            "| epoch   9 |  1000/ 1875 batches | lr 0.50000 | ms/batch 35.01 | loss  0.43 | accuracy    0.847\n",
            "| epoch   9 |  1500/ 1875 batches | lr 0.50000 | ms/batch 34.46 | loss  0.42 | accuracy    0.853\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 67.11s | valid loss  0.37 | valid accuracy    0.871 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |   500/ 1875 batches | lr 0.50000 | ms/batch 35.60 | loss  0.42 | accuracy    0.851\n",
            "| epoch  10 |  1000/ 1875 batches | lr 0.50000 | ms/batch 33.40 | loss  0.42 | accuracy    0.852\n",
            "| epoch  10 |  1500/ 1875 batches | lr 0.50000 | ms/batch 34.59 | loss  0.42 | accuracy    0.848\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 66.77s | valid loss  0.36 | valid accuracy    0.875 \n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}